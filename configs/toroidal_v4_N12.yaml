# V4 Toroidal Bottleneck: prediction flows THROUGH the torus
# Architecture: encoder -> torus_head (4D) -> torus_predictor -> predicted_torus
# This forces the encoder to maintain torus-compatible representations
# Expected: ~1.5h on RTX 4090

pretrained_checkpoint: "checkpoints/baseline_vicreg/best.pt"

model:
  embed_dim: 512
  hidden_dim: 1024
  ema_decay: 0.996
  torus_predictor_hidden: 64   # 4D -> 64D -> 64D -> 2 -> cos/sin -> 4D

training:
  epochs: 300
  batch_size: 256
  lr: 0.001
  weight_decay: 0.05
  warmup_epochs: 10
  num_workers: 4
  seed: 42

loss:
  type: toroidal_v4
  grid_size: 12
  lambda_std: 5.0        # Mild std loss on 512D encoder (just prevent collapse)
  lambda_torus: 25.0     # Strong uniformity on torus
  t_uniformity: 2.0
  spread_weight: 1.0

data:
  dataset: cifar10
  data_dir: ./data

output:
  dir: ./checkpoints/toroidal_v4_N12
  save_every: 50
